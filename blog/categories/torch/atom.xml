<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Torch | Mark Chang's Blog]]></title>
  <link href="http://ckmarkoh.github.io/blog/categories/torch/atom.xml" rel="self"/>
  <link href="http://ckmarkoh.github.io/"/>
  <updated>2016-12-25T13:22:22+08:00</updated>
  <id>http://ckmarkoh.github.io/</id>
  <author>
    <name><![CDATA[Mark Chang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Torch NN Tutorial 1 : NN.Module & NN.Linear]]></title>
    <link href="http://ckmarkoh.github.io/blog/2016/12/19/torch-nn-tutorial-1-nn-module/"/>
    <updated>2016-12-19T22:36:47+08:00</updated>
    <id>http://ckmarkoh.github.io/blog/2016/12/19/torch-nn-tutorial-1-nn-module</id>
    <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>此系列講解如何用 torch 實作 neural network 。</p>

<p>本系列不講解如何安裝 torch 及 lua 的基本語法，假設讀者都已具備這些基礎知識。</p>

<p>以 torch 實作 neural network 時，最常用的套件為 <a href="https://github.com/torch/nn">nn</a>，而在 <code>nn</code> 中，建構 neural network 最基本的單位為 <a href="https://github.com/torch/nn/blob/master/Module.lua">nn.Module</a> 。 <code>nn.Module</code> 是一個抽象類別，所有建構 neural network 本身有關的 module ，都是從 <code>nn.Module</code> 所繼承而來。</p>

<p>舉個例子，如果要實作以下運算：</p>

<script type="math/tex; mode=display">

\textbf{y} = \textbf{W}\textbf{x} + \textbf{b} 

</script>

<p>假設 <script type="math/tex">\textbf{x}</script> 為 2 維的 input ，而 <script type="math/tex">\textbf{y}</script> 為 3 維的output， <script type="math/tex">\textbf{W},\textbf{b}</script> 分別為 weight 和 bias ，此兩參數皆以隨機值進行初始化。</p>

<p>使用 torch 實作此運算的方法如下：</p>

<p>首先，載入 nn 套件：</p>

<p><code>lua
require 'nn'
</code></p>

<p>建立一個 Linear Module：</p>

<p><code>lua
l1 = nn.Linear(2,3)
</code></p>

<!--more-->

<p>其中， <a href="https://github.com/torch/nn/blob/master/Linear.lua">nn.Linear</a> 即是用來進行 <script type="math/tex">\textbf{y} = \textbf{W}\textbf{x} + \textbf{b} </script> 這類的線性運算所用的模組，它繼承了 <code>nn.Module</code> 。 而 2 和 3 分別代表了 <script type="math/tex">\textbf{x}</script> 和 <script type="math/tex">\textbf{y}</script> 的維度。 當它被建構出來時， weight 和 bias 的值會以隨機值來初始化。 </p>

<p>以上程式中，建立一個命名為 <code>l1</code> 的 module ，如果要取得它的 weight 和 bias ，可以用 <code>l1.weight</code> 和 <code>l1.bias</code> 取得，方法如下：</p>

<p><code>lua
print(l1.weight)
print(l1.bias)
</code></p>

<p>執行結果如下：</p>

<p>```sh</p>

<p>0.1453  0.5062
 0.0635  0.4911
-0.1080  0.1747
[torch.DoubleTensor of size 3x2]</p>

<p>0.2063
-0.1635
-0.0883
[torch.DoubleTensor of size 3]</p>

<p>```</p>

<p>其中， size 3x2 的 tensor 為 weight, size 3 的 tensor 為 bias。</p>

<p>用此 module 可以執行運算，令 x 為一個二維向量 <script type="math/tex">[0,1]</script> ，輸入此 module ，進行 forward propagation ，也就是說，執行 <script type="math/tex">\textbf{y} = \textbf{W}\textbf{x} + \textbf{b} </script> 的運算， 並輸出結果為 <script type="math/tex">\textbf{y}</script>  ，實作如下：</p>

<p>```lua</p>

<p>x = torch.Tensor{0,1}
y = l1:forward(x)
print(y)</p>

<p>```</p>

<p>輸出結果 <code>y</code> 為一個三維向量，如下：</p>

<p>```sh
 0.7125
 0.3276
 0.0865
[torch.DoubleTensor of size 3]</p>

<p>```</p>

<p>也可以從 <code>l1.output</code> 來直接取得 <code>l1</code> 之前進行運算的結果。</p>

<p><code>lua
print(l1.output)
</code></p>

<p>結果如下：</p>

<p><code>sh
 0.7125
 0.3276
 0.0865
[torch.DoubleTensor of size 3]
</code></p>

<h2 id="nnmodule--nnlinear">nn.Module &amp; nn.Linear</h2>

<p>這邊要更進一步介紹 <code>nn.Module</code> 和 <code>nn.Linear</code> 的內容是什麼。由於 torch 的源碼相當簡潔易懂，可以直接看源碼來了解它的功能是什麼。</p>

<p><code>nn.Module</code> 源碼： <a href="https://github.com/torch/nn/blob/master/Module.lua">https://github.com/torch/nn/blob/master/Module.lua</a></p>

<p><code>nn.Linear</code> 源碼： <a href="https://github.com/torch/nn/blob/master/Linear.lua">https://github.com/torch/nn/blob/master/Linear.lua</a></p>

<p>首先，介紹 <code>nn.Module</code> ，先看 <code>init()</code> 的部分：</p>

<p><code>lua nn/Module.lua
function Module:__init()
   self.gradInput = torch.Tensor()
   self.output = torch.Tensor()
   self._type = self.output:type()
end
</code></p>

<p><code>Module</code> 中最基本的成員有 <code>output</code> 和 <code>gradInput</code> 。
<code>output</code> 為此 <code>Module</code> 的 forward propagation 結果，而 <code>gradInput</code> 為 backward propagation 的運算結果。
這些變量一開始都會被初始化為 空的 tensor 。</p>

<p>註：本文先不講解 backward propagation 與 <code>gradInput</code> 的部分，交由之後的教學文章來解釋。</p>

<p>在 <code>Module:forward</code> 的部分，是用來進行 forward propagation的，如下：</p>

<p>```lua nn/Module.lua</p>

<p>function Module:updateOutput(input)
   return self.output
end</p>

<p>function Module:forward(input)
   return self:updateOutput(input)
end</p>

<p>```</p>

<p>先看 forward 的部分， Module 沒有運算的實作，僅單純輸出 <code>output</code> 值。如果呼叫了 forward propagation ，則從 <code>Module:updateOutput</code> 就直接輸出了 <code>output</code> 。</p>

<p>而 <code>nn.Linear</code> 則實作了 forward propagation。</p>

<p>所謂的 Linear，即是指 <script type="math/tex">\textbf{y} = \textbf{W}\textbf{x} + \textbf{b} </script> 的線性運算。</p>

<p>再來看 <code>nn.Linear</code> 的程式碼，先看 <code>init()</code> 的部分：</p>

<p>```lua nn/Linear.lua</p>

<p>local Linear, parent = torch.class(‘nn.Linear’, ‘nn.Module’)</p>

<p>function Linear:__init(inputSize, outputSize, bias)
   parent.__init(self)
   local bias = ((bias == nil) and true) or bias
   self.weight = torch.Tensor(outputSize, inputSize)
   self.gradWeight = torch.Tensor(outputSize, inputSize)
   if bias then
      self.bias = torch.Tensor(outputSize)
      self.gradBias = torch.Tensor(outputSize)
   end
   self:reset()
end</p>

<p>```</p>

<p>在第1行， <code>nn.Linear</code> 繼承了 <code>nn.Module</code> 。</p>

<p>在第3行開始可以看到，建構 Linear 所需的參數有 <code>inputSize</code> , <code>outputSize</code> 和 <code>bias</code> 。 <code>bias</code>  不一定要給，如果沒有給，則預設值會讓它是隨機的。除非 <code>bias=false</code> ，則此 Linear Module 就不會有 <code>bias</code> 。
從6~10行中，它比 <code>nn.Module</code> 多了 <code>weigt</code> 和 <code>bias</code> 這兩個變量，而 <code>reset()</code> 則是將它們初始化。</p>

<p>如果要建立一個 Linear Module，則要給定 <code>inputSize</code> 和 <code>outputSize</code> ，也就是 <script type="math/tex">\textbf{x}</script> 和 <script type="math/tex">\textbf{y}</script> 的維度。</p>

<p>假設  <script type="math/tex">\textbf{x}</script> 是二維， <script type="math/tex">\textbf{y}</script> 是三維，建立一個命名為 <code>l2</code> 的 Linear 模組：</p>

<p><code>lua
l2 = nn.Linear(2,3)
</code></p>

<p>用以下方法印出 l2 的 <code>weight</code> , <code>bias</code> 和 <code>output</code> ：</p>

<p><code>lua
print(l2.weight)
print(l2.bias)
print(l2.output)
</code></p>

<p>輸出結果如下：</p>

<p>```sh
-0.2863  0.5541
-0.6269  0.6557
-0.3215 -0.1648
[torch.DoubleTensor of size 3x2]</p>

<p>-0.0316
 0.4126
 0.4415
[torch.DoubleTensor of size 3]</p>

<p>[torch.DoubleTensor with no dimension]</p>

<p>```</p>

<p>其中，<code>weight</code> 和 <code>bias</code> 會被初始化隨機成 size 3x2 和 size 3 的 double tensor ，而最後一行顯示出 <code>output</code> 還是空的（with no dimension）。</p>

<p>要讓 <code>output</code> 有值，就要進行 forward propagation 。而 <code>Linear:updateOutput</code> 則是實作了 <code>Module:updateOutput</code> 中， forward propagation 運算的實際內容，程式碼如下：</p>

<p>```lua nn/Linear.lua</p>

<p>function Linear:updateOutput(input)
   if input:dim() == 1 then
      self.output:resize(self.weight:size(1))
      if self.bias then self.output:copy(self.bias) else self.output:zero() end
      self.output:addmv(1, self.weight, input)
   elseif input:dim() == 2 then
      local nframe = input:size(1)
      local nElement = self.output:nElement()
      self.output:resize(nframe, self.weight:size(1))
      if self.output:nElement() ~= nElement then
         self.output:zero()
      end
      updateAddBuffer(self, input)
      self.output:addmm(0, self.output, 1, input, self.weight:t())
      if self.bias then self.output:addr(1, self.addBuffer, self.bias) end
   else
      error(‘input must be vector or matrix’)
   end</p>

<p>return self.output
end
```</p>

<p>以上可以分為兩部分來看，首先是當 <code>input:dim() ==1</code> 時，也就是 <code>input</code> 的維度為 1 ，也就是一次只輸入單筆資料的時候。第一步，會先調整 <code>output</code> 的 <code>size</code> 為適當的大小，再將 <code>bias</code> 複製到 <code>output</code> ，再讓 <code>input</code> 和 <code>weight</code> 進行矩陣相乘，並和 <code>output</code> 相加，再輸出結果。</p>

<p>從數學公式上來看，輸入值 <script type="math/tex">\textbf{x}</script> 是一維的向量，進行的運算如下：</p>

<script type="math/tex; mode=display">
\textbf{W}\textbf{x} + \textbf{b}
</script>

<p>此時， <script type="math/tex">\textbf{W}</script> 放前面，而 <script type="math/tex">\textbf{x}</script> 放後面。</p>

<p>例如當輸入值向量 <script type="math/tex">[0,1]</script> 時，則矩陣運算的結果為：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
&\begin{bmatrix}
-0.2863 & 0.5541 \\
-0.6269 & 0.6557 \\
-0.3215 & -0.1648 \\
\end{bmatrix}
\begin{bmatrix}
0 \\
1
\end{bmatrix}
+ 
\begin{bmatrix}
-0.0316 \\
 0.4126 \\
 0.4415 \\
\end{bmatrix}
=
\begin{bmatrix}
-0.2863 \times 0 + 0.5541 \times 1  -0.0316 \\
-0.6269 \times 0 + 0.6557 \times 1 + 0.4126\\
-0.3215 \times 0  -0.1648 \times 1 + 0.4415\\
\end{bmatrix}\\
&=
\begin{bmatrix}
0.5541 -0.0316 \\
0.6557 + 0.4126\\
-0.1648 + 0.4415\\
\end{bmatrix}
=
\begin{bmatrix}
  0.5225 \\
  1.0683  \\
  0.2766 \\
\end{bmatrix}
\end{align}

 %]]&gt;</script>

<p>實作以上算式，呼叫 <code>l2:forward</code> ，輸入 <code>torch.Tensor{0,1}</code> 並印出結果：</p>

<p><code>lua
print(l2:forward(torch.Tensor{0,1}))
</code></p>

<p>結果如下：</p>

<p><code>sh
 0.5225
 1.0683
 0.2766
[torch.DoubleTensor of size 3]
</code></p>

<p>這時已經進行過了 forward 運算，而 <code>output</code> 有值了，所以可以印出它的值，方法如下：</p>

<p><code>lua
print(l2.output)
</code></p>

<p><code>output</code> 的值也是如下：</p>

<p><code>sh
 0.5225
 1.0683
 0.2766
[torch.DoubleTensor of size 3]
</code></p>

<p>而當 <code>input:dim() ==2</code> 時，也就是 <code>input</code> 的維度為 2 ，也就是一次輸入多筆資料。這時需要先把 <code>weight</code> 進行轉置，再和 <code>input</code> ，並和 <code>bias</code> 相加，並將結果加到 <code>output</code> 並輸出。</p>

<p>一次輸入多筆資料的目的是為了加速運算，因為用矩陣對矩陣的相乘的方式就可以來加速。這樣同時輸入的一批資料，就稱為 batch 。</p>

<p>從公式上來看，輸入值 <script type="math/tex">\textbf{X}</script> 是二維的矩陣，則進行以下矩陣運算：</p>

<script type="math/tex; mode=display">
\textbf{X}\textbf{W}^{T} + \textbf{B}
</script>

<p>此時， <script type="math/tex">\textbf{X}</script> 放前面，而 <script type="math/tex">\textbf{W}</script> 進行轉置後放後面。</p>

<p>而 <script type="math/tex">\textbf{B}</script> 是將 <script type="math/tex">\textbf{b}</script> 轉置以後，再複製其橫排所形成的矩陣，以便和前面的矩陣相乘結果來相加。</p>

<p>例如當輸入資料有兩筆向量 <script type="math/tex">[0, 1]</script> 和 <script type="math/tex">[2, 1]</script> 時，則可以組成以下矩陣 (2x2) ：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{bmatrix}
0 &1 \\
2 &1 \\
\end{bmatrix}


 %]]&gt;</script>

<p>則矩陣運算的過程如下：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align}
&
\begin{bmatrix}
0 &1 \\
2 &1 \\
\end{bmatrix}
\begin{bmatrix}
-0.2863 & -0.6269 & -0.3215 \\
 0.5541 & 0.6557 & -0.1648 \\
 \end{bmatrix}
+ 
\begin{bmatrix}
-0.0316 & 0.4126 & 0.4415 \\
-0.0316 & 0.4126 & 0.4415 
\end{bmatrix}\\
&
=
\begin{bmatrix}
   -0.2863 \times 0 +  0.5541 \times 1
&  -0.6269 \times 0 +  0.6557 \times 1
&  -0.3215 \times 0   -0.1648 \times 1\\

   -0.2863 \times 2 +  0.5541 \times 1
&  -0.6269 \times 2 +  0.6557 \times 1
&  -0.3215 \times 2   -0.1648 \times 1\\
\end{bmatrix}\\
&
+ 
\begin{bmatrix}
-0.0316 & 0.4126 & 0.4415 \\
-0.0316 & 0.4126 & 0.4415 
\end{bmatrix}\\
&
=
\begin{bmatrix}
0.5541 -0.0316
& 0.6557 +0.4126
& -0.1648 +0.4415 \\
-0.0186  -0.0316
& -0.5981 +0.4126
& -0.8079 +0.4415 \\
\end{bmatrix}\\
&
=
\begin{bmatrix}
 0.5225 & 1.0683  & 0.2766 \\
-0.0502 & -0.1855 & -0.3664 \\
\end{bmatrix}
\end{align}\\

 %]]&gt;</script>

<p>輸出結果為一個 2x3 的矩陣，每一個橫排為一個三維向量，代表著每一筆資料經過線性運算的結果。</p>

<p>實作以上算式，呼叫 <code>l2:forward</code> ，輸入由 <code>{0,1}</code> 和 <code>{2,1}</code> 這兩筆資料組成的 batch， 並印出結果：</p>

<p>{% raw %}
<code>lua
input={
   {0,1},
   {2,1}
}
print(l2:forward(torch.Tensor(input)))
</code>
{% endraw %}</p>

<p>結果如下：</p>

<p><code>sh
 0.5225  1.0683  0.2766
-0.0502 -0.1855 -0.3664
[torch.DoubleTensor of size 2x3]
</code></p>

<p>也可印出 <code>output</code> 的值：</p>

<p><code>lua
print(l2.output)
</code></p>

<p>結果如下：</p>

<p><code>sh
 0.5225  1.0683  0.2766
-0.0502 -0.1855 -0.3664
[torch.DoubleTensor of size 2x3]
</code></p>

<h2 id="materials">Materials</h2>

<p>本次教學的完整程式碼於此：</p>

<p><a href="https://github.com/ckmarkoh/torch_nn_tutorials/blob/master/1_nn_module_and_linear.ipynb">https://github.com/ckmarkoh/torch_nn_tutorials/blob/master/1_nn_module_and_linear.ipynb</a></p>

]]></content>
  </entry>
  
</feed>
